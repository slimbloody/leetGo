公司的现在的体量, 高峰期日订单量上百万高的时候(150w), 日gmv过亿, 详情访问量单节点qps有100多

日访问量有2k多w 


========================================
总体架构
========================================
WAF -> LVS -> nginx -> gateway -> Entry application -> support application -> storage

========================================
大单体拆分
========================================
早期是在大单体上面开发的. 在大单体上面开发, 效率比较低
1. 单体启动速度非常慢, 启动一下要十几分钟, 本地调试和线上故障响应速度都相应被拖慢了, 
2. 协同不方便, 可能一个同事改了代码, 另一个同事在提交的时候又发现有冲突了
3. 扩展能力受限, 无法按需伸缩, 单体应用只能作为一个整体进行扩展, 无法结合业务模块的特点进行伸缩
4. 可靠性差, 可能因为某个同事写出了bug, 单体crash了, 整个服务都不可用了

根据业务类型, 大致分为了
活动组: 门户, 主管活动的发布浏览, 商品发布浏览
主页组: feed流, 团长和成员的关系, 团长之间的关系
通知组: 通知推送, 订阅关系, 开放平台
订单组: 下单的正向, 逆向流程, 物流, 签到, 短信
运营后台组: 企业微信插件的开发, 运营后台以及一些IM工作
大数据组: 主管大数据业务, 主要生成一些报表信息或者为其他组提供支持工作
架构组: 提供一些基础架构升级, 风控以及审核业务

各组都根据自己负责的模块去拆分对应的接口.

拆分思路:
1. 快速拆出各个组的核心接口, 保证核心流程高可用
2. 在核心流程拆出来以后, 看看大单体还有没有什么访问量比较高的接口
解决这些瓶颈后, 大单体的拆分就不是最紧要的工作了, 以日常开发业务为先, 有空就迁一点出来, 让大单体最后慢慢消亡.

========================================
定时扩容
========================================

观察了一下用户的流量分布, 一般早上10点开始到中午12点和晚上8点到10点都是高峰期, 这个时候数据库的性能还有很多剩余(多个库都是16核128G的), 为了应对高的流量, 一般早上9点开始到中午12点和晚上7点到晚上11点都会定时扩容.

担心有些库日后可能会有数据库性能的问题, 同期也有做一些库表迁移, 把一些iops高的, 但是不紧要的表不停机迁移出去, 如果业务不紧要, 我就直接把一些表砍掉, 比如幂等表.

如何做mysql数据迁移
1. 双写
2. 存量数据迁移
3. 用旧接口双读对比
4. 抽样单读
5. 单读
6. rename 数据表
7. drop 表

todo:
如何做es数据迁移
1. 索引想加字段
   1. 磁盘空间大, 内存剩余量多, 低峰期reindex(5000w数据大概是40min)
2. 节点性能已经不够了, 要升级节点并且加字段
   1. 直接迁移, 如何压榨写性能

todo:
es索引, es读写数据(官方文档)

如何预估规格: 存量估增量(过去几个月多少, 现在能到多少), 稍微提高一点


========================================
应用被打垮
========================================
之前经常碰到应用被打垮的情况. 这里解释一下什么是应用被打垮. 真正的应用crash要不就是OOM或者 StackOverFlow这种, 应用直接挂掉了. 然而在分布式系统中, 一般都是监控那边发心跳请求给应用, 多次没有响应(我们暂定为4次, 间隔为15s, 5s内一定要给响应), 那么k8s就认为应用已经crash了, 要重启这个节点. 实际上可能出现的事情是, tomcat线程池打满, 同时等待队列也被打满了, 请求被丢弃了, 或者说这种验活请求打到了tomcat的等待队列里面, 但是前面的请求没有处理完, 一直没能响应这个验活请求.

为了解决这个问题, 我们就开始想, 能不能我的验活请求和业务请求分开, 由这个想到说tomcat请求都是从connector这边进来的, 如果我的验活请求或者prometheus监控数据的采集单独分配一个connector, 有自己的独立线程池, 就能解决这个问题. 独立线程池的工作线程数我配少一点嘛, 活跃线程配个5, max配给10足够了.

这个时候还碰到过这种问题, 有个consumer服务是多线程拉取消息处理的, 没有设置阻塞队列大小, 在io密集的业务场景下, 下游服务阻塞, 会导致大量消息堆积到内存中, 最后jvm一直在fullGC, 这种情况下 也没法及时响应liveness probe, 这种属于代码写的有问题的, 所以应用也应该被kill掉重启. 对应小组在应用被kill掉以后会收到钉钉告警, 如果是超过晚上22点会收到告警电话.


========================================
限流
========================================
上了这个以后, 应用被打垮的情况大大减少了. 但是在请求量高的时候, 节点依然腾不出资源给探针响应.
考虑到电商业务场景和腾讯会议那种不一样, 腾讯会议是一小组的用户长时间占用资源, 但电商场景不一样, 单次读完活动信息和商品信息就结束了.
我们是服务提供商, 不可能为这些单一租户提供无限的服务资源的, 所以这个场景做限流是比较合适. 我们这边有类似分销场景, 最高能到三级, 如果超过三级就成传销了. 之前经常有这种情况, 多个活动同时在固定时间点涌进来, 比如晚上8点, 母团子团孙团的用户, 同时在这个时候进来, 看活动详情, 商品详情, 然后下单的, 这个时候我们就对同一母团的活动进行限流. 限流之后就没有这个问题了.


========================================
限流框架选了sentinel
========================================
1. 为什么限流
2. 一般限流会怎么做
3. 为什么选sentinel
   1. java
   2. 阿里
4. sentinel怎么做限流
5. 试用hystrix当时碰到的问题: trace传不进去

========================================
微信自适应限流
========================================
1. 业务怎么通过操作分级(具体业务具体分析)肯定是登陆 > 支付 > 下订单
2. 函数设计, 要让不同机器上面的优先级算出来都一样,每个机器可能自带一张相同的随机数表, 为了避免time drift一定要用nanotime作为seed
3. 最后限流算法的区间是怎么取的

========================================
单节点顶更多的请求
========================================
首先大部分请求瓶颈都在io上, 关键在于数据库的响应.
最早想的是把4C8G的2节点拆出2C4G的4节点, 这样线程数就翻了一倍
后面想到节点虚拟化需要资源的, 为什么如果要靠这样让总的线程数提升, 为什么不直接调高tomcat的线程数, core线程数和max线程数都可以调大
如果把所有资源都给到一个节点上面, SPF
总结: 给节点配合理的资源很重要

1. 数据库查询更快
   1. 加索引(失败了全部回滚, algorithm=unlock是什么样的)
   2. 拆宽表为长表(减少io的量, 可以把压力给到其他库上面)
2. 加缓存(有些地方是不方便加缓存的)
   1. ds层上层加一个封装, 先写cache层, 通过mq异步把cache刷到mysql里面去
      为什么用ds
      1. 
      2.
   2. 有些接口失效
   3. 应用外接缓存
   
2. 耗时长的请求异步



========================================
优化
========================================
应用保证可用性以后, 就开始对性能进行优化了


========================================
日后优化
========================================
1. 冷热数据分离, 因为这个看到了haystack(long tail)和f4(warm,hot)

   
========================================
技术问题上面的优化
========================================
1. 慢查询
2. 慢响应
3. 

========================================
业务问题上面的优化
========================================
1. 顺丰物流多个管理员发订单的锁, 之前一直在想怎么锁, 后来一想, 只要把发订单的uid给出去就行了, 让用户自己去处理
2. sys-mina项目引用了一个包画图, 这个包可能有内存泄露, 因为old区每次回收以后, 都比上次old区剩余的对象要多, 而且这个应用的对象大部分都是朝生夕灭的, 排查又没有时间, 就原样复制了一个应用出来, 但是应用名不同, 这个新的应用只处理画图, 到了凌晨4点的时候, 换一个新的画图应用(优雅下线, 会等应用处理完自己内部的请求以后在结束, 把量切到一个新的应用里面去)
3. 第一次分享活动有一个画图的业务, 画图比较慢, 并且是集中在晚上大概七八点的时候, 因为画图没画出来活动是不能分享的, 所以团长会投诉.
   1. 因为分享过的活动是有图的, 即使不重新画图也能分享, 所以分享过的活动再更新图片, 这类请求在高峰期可以抛弃, 把资源集中给新的活动. 
   2. 因为图像迟迟没有画出来, 用户可能会连着画好几次, 服务器重复处理这个请求. 加了一个画图的锁解决这个问题, 在上一个图画完之前锁没有释放, 就不能加锁.

========================================
项目上面的优化
========================================
1. 开源节流
开源:
   1. 对接顺丰物流返现
节流:
   1. 快递100查询要收费, 改用免费的微信物流

========================================
在公司看重的点
========================================
1. 新业务产生了效益(比重最大, 让公司有了增长点)(开源)
2. 确确实实用技术降低了公司的成本(节流)
3. 核心业务不出错, 正常使用(bug-free)
4. 人员管理方面, 如何在资源不足的情况下驱动组员(项目动员会, 讲清楚为什么要做这个事情, 更深远的影响)
5. 梯队培养, 快速培养一个核心的人员出来(文档描述清晰, 语言规范)
6. 技术积累, 自己组方案可不可以复用到其他组里面去

































