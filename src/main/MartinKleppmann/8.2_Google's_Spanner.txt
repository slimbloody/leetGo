
so we've talked about these eventually consistent systems, for the last section, let's switch back to very strongly consistent systems.

=====================================
Google's Spanner
=====================================
A database system with millions of nodes, petabytes of data, distributed across datacenters worldwide(spread all around the globe) (despite this huge scale, we want to achieve very strong consistency properties in this database)
------------------------------------------------------------------
and what I'd like to tell you about is a very interesting database system developed by google called Spanner. This is a very large-scale database systems, it's intended to be used with huge amounts of data with millions of nodes, spread all around the globe, despite this huge scale, we want to achieve very strong consistency properties in this database.
in particular, the classic that we've seen, we want serializable transaction isolation, the strongest isolation we can get. we want linearizability for reads and writes that means we're always going to see an up-to-date value from any value written.


------------------------------------------------------------------
Consistency properties:
    1. Serializable: transaction isolation(strongest isolation we can get)
    2. Linearizable: reads and writes(we're always going to see an up-to-date value from any value written)
    3. Many shards, each holding a subset of the data; atomic commit of transactions across shards
------------------------------------------------------------------
moreover, we need to support sharding which means that this huge amount of data which is far too much to store on a single node, we have to split into subsets of data, each node has a replica of a subset of the data.
so that now you can distribute the data across all of these different nodes, but this now means that you might have a transaction needs to read and write data on multiple nodes. and if this happens, distribute a transaction like this, we need atomic commit, so that any changes made by a transaction will either be committed on all of the nodes or aborted on all of nodes.

------------------------------------------------------------------
Many standard techniques:
    State machine replication (Paxos) within a shard
    Two-phase locking for serializability
    Two-phase commit for cross shard atomicity
------------------------------------------------------------------
so all of these classic properties we want and a lot of the techniques that Spanner uses to implement these properties are equally classic standard algorithms.

in order to replicate the nodes within a shard, it uses state machine replication, it uses the Paxos consensus algorithm rather than raft, but they are reasonably similar and the principle are very much the same.

in order to achieve serializable transaction isolation, we use the classic two-phase locking that means for any reads we take a shared lock on any data we want to read, and for any writes, we'd need to take an exclusive lock on any data that we write and we need to hold those locks until the transaction commits.

Finally in order to achieve atomicity across multiple shards, we do the classic, we do two-phase commit exactly like we saw in the last lecture.

------------------------------------------------------------------
The interesting bit: read-only transactions require no locks!
------------------------------------------------------------------
so far, implementing all of these things is still a significant engineering challenge but there's nothing conceptually very new here, where spanner gets interesting is that it has support for read-only transactions that take no locks.
now this is special, because if you remember what two-phase locking means, it means that if you want to read any data you first have to take a shared lock on that data, under shared lock is going to prevent any other transactions from updating that data.
but now in real systems, you often get very large read-only transactions, so for example taking a database backup is a very large read-only transaction, that needs to read essentially the entire database, that's what a backup is, it's a copy of the entire database. and so this backup may take a long time, and if you have to take a shared lock on the entire database for a long time while you're doing a database backup, then users are not going to like that very much, because it means that no writes can be made to the database for the entire duration of this backup.
so that would simply not fly in practice, we have to have some way of doing read-only transaction that does not require any locks, and the interesting of spanner is how it enables those kind of read-only transactions



so the way it works is those kind of read-only transactions can read from what is called a consistent snapshot.
=========================================
Consistent snapshots
=========================================
A read-only transaction observes a consistent snapshot:
If T1 -> T2 (e.g. T2 reads data written by T1)...
    Snapshot reflecting writes by T2 also reflects writes by T1
    Snapshot that does not reflect writes by T1 does not reflect writes by T2 either
    In other words, snapshot is consistent with causality
    Even if read-only transaction runs for a long time
------------------------------------------------------------------
consistent snapshot is a way of essentially looking at the entire database at one point in time, and the way it does this is using timestamp.
now important thing for this consistent snapshot, the consistent aspect is that it means we're consistent with causality, and so what I mean with this is if we have two transactions t1 and t2, and if t1 happened before t2, then if we have a snapshot that contains the writes that were made by t2, then that snapshot must also reflect the writes by t1, that means that we don't end up with some of the causal dependencies missing from the snapshot. likewise, if transaction does not contain the writes by t1, then it will not contain the writes by t2 either. so this goes both ways.
now this is what we mean with a snapshot being consistent with causality. it just means that we don't have bits of the database snapshot that don't make sense causally. so if the snapshot contains the effect then will also contain the cause of that effect. and so we want to ensure this consistent snapshot even if the read-only transaction runs for a long time, and without taking any locks.



------------------------------------------------------------------
Approach: multi-version concurrency control (MVCC)
    1. Each read-write transaction Tw has commit timestamp tw
    2. Every value is tagged with timestamp tw of transaction that wrote it (not overwriting previous value)
    3. Read-only transaction Tr has snapshot timestamp tr
    4. Tr ignores values with tw > tr; observes most recent value with tw < tp
------------------------------------------------------------------
and the way this is done is through approach called multi-version concurrency control(MVCC)
now MVCC is actually a very common technique it's used in lots of databases, including PostGres in mysql for example, the way it works is it attaches a timestamp to every transaction, and let's say that a read-write transaction has a timestamp tw and that timestamp is assigned at the time when that transaction commits. and then  any data that is written by this transaction tw is that any data is associated, it's a tagged with the transaction timestamp with the commit timestamp of the transaction that wrote it.
and now if we have an object that is being updated by a transaction, we won't simply overwrite that transaction in place, but we will make a new copy of that object, and that new version of the object will be tagged with timestamps tw of the transaction that wrote that version, but we will keep the old version of the object in place, in case there's a read-only transaction that actually needs to read the old version. and now, we associate each read-only transaction also with a timestamp, and that timestamp identifies the snapshot at which is the point in time at which that snapshot is observing the database.
and now, if the read-only transaction wants to read a particular object, it looks at the different versions of that object, each version tagged with a timestamp, it ignores any versions that have a timestamp greater than the snapshot timestamp, then those versions that have a timestamp less than or equal to the snapshot timestamp, it picks the highest, that is the version of the object that transaction is going to see. and so this now allows the read-only transaction to simply ignore any writes made concurrently. so the read-only transaction is going to see the entire database as of this particular time tr regardless whatever writes happen otherwise and without taking any locks.

now this works, this is very standard MVCC.

what is interesting about the way spanner implements this is the way these timestamps are generated.
===================================================
Obtaining commit timestamps
===================================================
Must ensure that wheneverT1 -> T2 we have t1 < t2.
    Physical clocks may be ###inconsistent with causality###
    Can we use Lamport clocks instead?
    Problem: linearizability depends on ###real-time order###, and logical clocks may not reflect this!
------------------------------------------------------------------
in order to ensure that our snapshot is causally consistent, what we require is that if transaction t1 happened before t2, then the timestamp of t1 has to be less then the timestamp of t2. but physical clocks do not guarantee this, so with physical clocks you could end up in a situation where transaction t1 happened before transaction t2, but t2 had a lower timestamp than t1, and we don't want this.
so we have to take some other measure to ensure that our timestamps are consistent with causality, the obvious answer is why don't we use logical clocks. because that's exactly what logical clocks were designed to do. unfortunately, logical clocks like lamport clock are not sufficient in this case either, and the reason for this is by this particular example.
let's say we have two replicas a and b, and the user executes some transaction t1 on replica a and then views the results of transaction, so the user has the results on the screen, then the user choose to perform some action, and that action results in some transaction t2 being executed on replica b.
so here very clearly it's the case that t1 happened before t2, because there's this user communication in the way the communication ensures that the action depends on the results from t1. so definitely, in this case, we want t1 to have a lower timestamp than t2. but if we're using lamport clocks, remember the way lamport clock work is they work by attaching a timestamp to every message that is sent over the network. and then when you receive one of those messages, you bump up your own local clock to the maximum of the local timestamp and the one you received, but in this case here, there might not be any communication between replicas a and b, so replica a may never send any message to replica b while this is happening because communication is going by a user. and so there's nothing that can propagate our timestamps from a to b. because there's no message that can propagate the timestamps, and we can't rely on the user like type in timestamps or something like that here
so replica b may not actually realize that it needs to have a timestamp for t2 that is higher than the timestamp of t1, because there's nothing passing along these timestamps that we would need for lamport clocks.



so lamport clock don't work either, so what can we do in this case.
well, we can go back to physical clocks, but we have to adjust the physical clocks and do some extra message in order to make sure that this causal ordering property here is satisfied.
the way spanner does this is using a system called TrueTime.
===============================================================
TrueTime: explicit physical clock uncertainty
===============================================================
Spanner's TrueTime clock returns [t(earliest)ï¼Œt(latest)]
True physical timestamp must lie within that range.

TrueTime is a system of physical clocks, that explicitly captures uncertainty in the timestamps
and the way this works is say replica a wants to commit transaction t1, at the time when it wants to commit that transaction. the replica requests a time from TrueTime, and TrueTime does not reply with simply a single timestamp but it returns a range, it return two timestamp, the earliest possible and the latest possible. and so because of the uncertainties, there's no perfect synchronization of clocks in the systems that we have, we can never be totally certain about what the current real physical timestamp is, but we can track all of the errors in the system and all of the uncertainty in the system, and if we correctly account for the uncertainty, then we can be sure that the real physical timestamp will be somewhere between this earliest possible and latest possible with very high probability. so this means we have to track like the round trip time to the clock server, we need to write account for clock drift, we have to account for any sort of things that might cause error. add up all of those potential causes of error, and factor this all into a single uncertainty interval, so that we know that the real timestamp lies somewhere in between this early as possible and the latest possible.
and now what spanner is going to do is it gets the pair of earliest and latest from TrueTime, and now it's going to wait, and the time it's going to wait is exactly the difference between the two timestamps, so this length of the uncertainty time interval called delta one, the transaction simply going to wait for that time, it's not going to do anything during that time. it's going to continue holding all of the locks. so the transaction is ready to commit, it just hasn't actually committed yet, and it's going to wait for this period delta one, and once that time has elapsed, now it commits it release all of the locks and it moves on. so this extra waiting is the key thing here.
now, let's say replica b wants to execute transaction t2, it does the same thing when it's ready to commit it requests timestamp from TrueTime, so it gets back an early as possible, and late as possible, and again it wait out uncertainty in this case delta two, the difference between the two timestamps
in this case here, we have this real-time dependency, so that t2 started after t1 ended, and the effect that this waiting has had is to ensure that if we have these two timestamps where there's a real-time dependency, then their uncertainty intervals from TrueTime will not overlap, because the uncertainty intervals do not overlap, this mean now that the commit timestamp for t1 will definitely be a lower timestamp than the commit timestamp of t2 by having these uncertainty periods non-overlapping we have got rid of possibility of the timestamps getting reordered and thus being inconsistent with causality.

so the key here is this waiting, and of course in a real system, we want to wait for a short time as possible. so we now need to do two things:
firstly, we need to precisely quantify the uncertainty so that we know how long we have to wait
secondly, we have to keep the uncertainty as small as possible, so that our waiting time is as short as possible,



and way that TrueTime does this is by actually putting atomic clocks and gps receivers in every datacenter, and these cost some money of course, but Google has figured out they're actually affordable enough. this give each datacenter a reliable clock source, and now every other node in the data center that is not directly connected to these reliable clocks, every normal node just has the usual quartz clock, and it is going to periodically synchronize it's local quartz clock with the time server that has the atomic clock or the gps receiver attached. and TrueTime actually performs this clock synchronization every 30 seconds. and so every 30 seconds, there's going to be like a ping from each node in the data center to its local time server.
===================================================
Determining clock uncertainty in True Time
===================================================
Clock servers with atomic clock or GPS receiver in each datacenter; servers report their clock uncertainty.

Each node syncs its quartz clock with a server every 30 sec.

----------------------------------------------------
and result is that every time that clock synchronization is performed, the uncertainty drops down because the uncertainty now is just essentially the round trip time to the server plus any uncertainty that the server had about its own time, and so because we're assuming that here the time server is in the local datacenter, locally the round trip time to the clock server will usually be less than one millisecond, because there are no big geographic distances to be covered here. therefore, whenever we sync with the clock server, the uncertainty about our clock about local clock drops down to about one millisecond, and then in between in these 30 second intervals between the synchronization, it depends on the rate at which the local clock drifts with respect to the actual real time, and so for this google did some measurements and they figured out what is the worst case clock uncertainty that we have to assume to make sure that all of the clocks have a drift that is lower than this bound. they figured out that the worst case drift of 200ppm was a safe assumption to make. so this means here that in between these 30-second clock syncs, the uncertainty of each local clock keeps drifting up at a rate of 200ppm, so this means over the course of 30 seconds, we rack up about six milliseconds of clock uncertainty. and TrueTime keeps track of exactly how long it's been since the last synchronization. and therefore it has these uncertainty intervals keep widening and widening, until the next clock sync and the uncertainty drops back down to one millisecond, and then they start widening again and so on, we get this kind of sawtooth pattern here, and result is now that we have a very accurate notion of what our clock uncertainty is, which allows us to determine the wait time for each transaction, and moreover, because we're using these local accurate atomic clocks and gps receivers, the average time uncertainty is actually quite small, so the uncertainty interval average length is about four milliseconds, and so on average about four milliseconds is the time that the transaction needs to wait before it's allowed to commit, and four milliseconds is pretty short time actually, it's certainly a lot shorter the time it would take to do like a round trip time to a datacenter on a different continent which would take like 100 milliseconds or more. so this is really the key insight of spanner that we can use these reliable clocks and the careful measurement and accounting of uncertainty to ensure the timestamps are consistent with causality. now that we have timestamps that are consistent with causality, we get these causally consistent snapshots using multi-version concurrency control without taking any locks, therefore we can do these large-scale read transactions without any locks, so we can do database backups without disrupting any writes transactions that are happening in the database.
so you see here, this is sort of the stack of assumptions and combinations of algorithms that you get in real systems. but this is very concrete and very widely used system, that is widely deployed in practice, and you can see how all these distributed systems concepts come together in a single system which I find very exciting.


















