============================================
2.2 The Byzantine generals problem
============================================
problem: some of the generals might be traitors



we make problem easier in one way and harder in another way.
1. (easier) we assume the messengers are reliable
any message that gets sent will actually be received by the appropriate recipient
2. (harder) some of the general are not loyal, being malicious
they are going to try to activity undermine the other generals, so they are going to lie and deceive, and generally misbehave in any sort of way as they wish, they might even work together
and nevertheless, we want the honest generals to come to agreement about the attack of the city




=============================
Generals that might lie
=============================
general1 -> general2: attack
general1 -> general3: attack
general2 -> general3: general1 said retreat

general2 is malicious, unfortunately, for points of view of general3, it's impossible to tell the difference between these two scenarios


general1 -> general2: retreat
general1 -> general3: attack
general2 -> general3: general1 said retreat
general2 is being honest because general2 is just reporting honestly what general1 said, and it's general one who is being malicious by sending contradictory commands to general2 and general3



core:
for points of view of general3, it's impossible to tell the difference between these two scenarios

now given this scenario where nodes might lie
----------------------------------------------------------------
Byzantine General Problem:
1. Up to f generals might behave maliciously
2. Honest generals don't know who the malicious ones are
3. The malicious generals may collude
4. Nevertheless, honest generals must agree on plan

honest generals don't know who the malicious generals are, but we going to assume some maximum number of generals being malicious
f generals out of n generals in total

honest generals don't know who the malicious generals are,
but malicious generals may know who the other militias generals are, so they might actually work together in some coordinate fashion to try to deceive and trick the honest generals.

and nevertheless our requirement is that the honest generals agree on a plan
so we can't get malicious generals to agree on any part of the plan, because we assuming that they might misbehave in arbitrary ways


============
todo: 证明这个数值
Theorem: need 3f + 1 generals in total to tolerate f malicious generals (i.e. < 1/3 be malicious)
Cryptography (digital signatures) helps - but problem remains hard
============
a digital signature which is a form of message in which it can be proved that a certain party sent a certain message
in this case, it allows general 2 to prove what a command general 1 sent to general 2, and prove that to general 3 in a way that general 3 would be convinced that general 2 really is honest

todo: 怎么用这个签名的



==============================================
Trust relationships and malicious behaviour
==============================================
customer, online shop and the payments service are the third party, so we have this kind of three-way relationship between the shop, the payment service and customer, and we want all three of these parties to agree on the status of transaction or status of an order.



from the point of view of the online shop, the customer needs to be treated as potentially malicious, because if the customer was just blindly trusted, then they might start doing fraudulent activity like that, so in that case we do have this kind of untrusting relationship, what about the online shop and payment service relationships? you can imagine maybe the payment service doesn't quite trust the online shop because otherwise someone might set up a fraudulent online shop, use stolen credit card number try to process transactions, and get money without actually shipping any real goods, so in that case, probably the payment service doesn't fully trust online shop, but maybe the shop does trust the payment service, so it might be this kind of asymmetric relationship.
the trust relationship in real life get rather complicated, you do end up in these situations where one party does not trust another party, and they nevertheless want to get something done, and so in that sense, byzantine behaviour is real and practical.

the byzantine general's problem is of course a simplification of this kind of scenario, because it's treating all of the generals as symmetric for example, but nevertheless, the byzantine generals problem is a useful starting point, for studying these kind of situations in which the participants don't fully trust each other.











-------------------------------------------------------------------------------

The Byzantine generals problem [Lamport et al., 1982] has a similar setting to the two generals problem. Again we have armies wanting to capture a city, though in this case there can be three or more. Again generals communicate by messengers, although this time we assume that if a message is sent, it is always delivered correctly



The challenge in the Byzantine setting is that some generals might be “traitors”: that is, they might try to deliberately and maliciously mislead and confuse the other generals. One example of such malicious behaviour is shown on Slide 27: here, general 3 receives two contradictory messages from generals 1 and 2. General 1 tells general 3 to attack, whereas general 2 claims that general 1 ordered a retreat. It is impossible for general 3 to determine whether general 2 is lying (the first case), or whether general 2 is honest while general 1 is issuing contradictory orders (the second case).


The honest generals don’t know who the malicious generals are, but the malicious generals may collude and secretly coordinate their actions. We might even assume that all of the malicious generals are controlled by an evil adversary. The Byzantine generals problem is then to ensure that all honest generals agree on the same plan (e.g. whether to attack or to retreat). It is impossible to specify what the malicious generals are going to do, so the best we can manage is to get the honest generals to agree.



This is difficult: in fact, it can be proved that some variants of the problem can be solved only if strictly fewer than one third of the generals are malicious. That is, in a system with 3f + 1 generals, no more than f may be malicious. For example, a system with 4 generals can tolerate f = 1 malicious general, and a system with 7 generals can tolerate f = 2.


The problem is made somewhat easier if generals use cryptography (digital signatures) to prove who said what: for example, this would allow general 2 to prove to general 3 what general 1's order was, and thus demonstrate general 2’s honesty. We will not go into details of digital signatures in this course, as they are covered in the Security course (Part IB Easter term). However, even with signatures, the Byzantine generals problem remains challenging.

Is the Byzantine generals problem of practical relevance? Real distributed systems do often involve complex trust relationships. For example, a customer needs to trust an online shop to actually deliver the goods they ordered, although they can dispute the payment via their bank if the goods never arrive or if they get charged too much. But if an online shop somehow allowed customers to order goods without paying for them, this weakness would no doubt be exploited by fraudsters, so the shop must assume that customers are potentially malicious. On the other hand, for RPC between services belonging to the shop, running in the same datacenter, one service can probably trust the other services run by the same company. The payments service doesn’t fully trust the shop, since someone might set up a fraudulent shop or use stolen credit card numbers, but the shop probably does trust the payments service. And so on. And in the end, we want the customer, the online shop, and the payments service to agree on any order that is placed. The Byzantine generals problem is a simplification of such complex trust relationships, but it is a good starting point for studying systems in which some participants might behave maliciously.





















