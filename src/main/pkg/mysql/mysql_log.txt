=======================================
https://www.cnblogs.com/geaozhang/p/7241744.html
=================================================

逻辑日志: 可以简单理解为记录的就是sql语句
物理日志: mysql数据最终是保存在数据页中的,物理日志记录的就是数据页变更

binlog 用于记录数据库执行的写入性操作(不包括查询)信息,以二进制的形式保存在磁盘中.binlog 是 mysql 的逻辑日志

binlog使用场景
在实际应用中， binlog 的主要使用场景有两个，分别是 主从复制 和 数据恢复 。

主从复制: 在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致。
数据恢复: 通过使用 mysqlbinlog 工具来恢复数据。

bin_log格式:
1. STATMENT: 基于 SQL 语句的复制( statement-based replication, SBR )，每一条会修改数据的sql语句会记录到 binlog 中 。
    优点: 不需要记录每一行的变化，减少了` binlog ` 日志量，节约了 ` IO ` , 从而提高了性能
    缺点: 在某些情况下会导致主从数据不一致，比如执行` sysdate() ` 、 ` slepp() ` 等
    需要用到一些系统值的函数, 如果回放可能值不一样, 比如now()函数回放
2. 基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了
    优点: 不会出现某些特定情况下的存储过程,或function,或trigger的调用和触发无法被正确复制的问题
    缺点: 会产生大量的日志，尤其是 alter table 的时候会让日志暴涨
3. MIXED: 基于 STATMENT 和 ROW 两种模式的混合复制(mixed-based replication, MBR), 一般的复制使用 STATEMENT 模式保存 binlog , 对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog

sync_binlog配置
此项配置用来针对binlog的磁盘写入配置，可以用来配置合并多少条binlog一次性写入磁盘。
设置为0：代表依赖系统执行合并写入。
设置为1：代表每次提交事务后都需要写入，方案最安全，也是最慢的。
设置为N（一般100-1000）： 代表每N条后，合并写入磁盘。

针对sync_binlog，同样允许数据库服务器宕机的情况下能接受丢失N条数据的， 可以配置为N，能提高性能。

=================================================
https://segmentfault.com/a/1190000023827696
redo log
我们都知道，事务的四大特性里面有一个是 持久性 ，具体来说就是只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态 。那么 mysql是如何保证一致性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：
1. 因为 Innodb 是以 页 为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！
2. 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！

因此 mysql 设计了 redo log, 具体来说就是只记录事务对数据页做了哪些修改, 这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)

redo log 包括两部分：一个是内存中的日志缓冲(redo log buffer), 另一个是磁盘上的日志文件(redo log file).
 mysql 每执行一条 DML 语句，先将记录写入 redo log buffer, 后续某个时间点再一次性将多个操作记录写到 redo log file. 这种先写日志, 再写磁盘的技术就是MySQL里经常说到的 WAL(Write-Ahead Logging)技术。

在计算机操作系统中，用户空间(user space)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间(kernel space)缓冲区(OS Buffer). 因此, redo log buffer 写入 redo log file 实际上是先写入 OS Buffer, 然后再通过系统调用 fsync() 将其刷到 redo log file中

-------------------------------------------------

0(延迟写): 事务提交时不会将 redo log buffer 中日志写入到 os buffer ，而是每秒写入 os buffer 并调用 fsync() 写入到 redo log file 中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。
1(实时写,实时刷): 事务每次提交都会将 redo log buffer 中的日志写入 os buffer 并调用 fsync() 刷到 redo log file 中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。
2(实时写,延迟刷): 每次提交都仅写入到 os buffer,然后是每秒调用 fsync() 将 os buffer 中的日志写入到 redo log file 。

-------------------------------------------------

同时我们很容易得知, 在innodb中, 既有 redo log 需要刷盘, 还有 数据页 也需要刷盘, redo log 存在的意义主要就是降低对 数据页 刷盘的要求 . 在上图中， write pos 表示 redo log 当前记录的 LSN (逻辑序列号)位置， check point 表示 数据页更改记录** 刷盘后对应 redo log 所处的 LSN (逻辑序列号)位置。
Log Sequence Number

https://segmentfault.com/a/1190000023827696
write point:这个指针记录当前位置，一边写，一边移动，写到最后一个文件末尾后就回到 0 号文件重新覆盖写
check point:这个指针记录当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件

write pos 到 check point 之间的部分是 redo log 空着的部分，用于记录新的记录;
check point 到 write pos 之间是 redo log 待落盘的数据页更改记录.
当 write pos 追上 check point 时, 会先推动 check point 向前移动, 空出位置再记录新的日志.

启动 innodb 的时候, 不管上次是正常关闭还是异常关闭, 总是会进行恢复操作. 因为 redo log 记录的是数据页的物理变化, 因此恢复的时候速度比逻辑日志(如 binlog)要快很多.
重启 innodb 时, 首先会检查磁盘中数据页的 LSN, 如果数据页的 LSN 小于日志中的 LSN, 则会从 checkpoint 开始恢复
还有一种情况, 在宕机前正处于checkpoint 的刷盘过程, 且数据页的刷盘进度超过了日志页的刷盘进度, 此时会出现数据页中记录的 LSN 大于日志中的 LSN, 这时超出日志进度的部分将不会重做, 因为这本身就表示已经做过的事情, 无需再重做

-------------------------------------------------

redo log与binlog区别

        redo log	                                             binlog
文件大小	redo log 的大小是固定的                                     binlog 可通过配置参数 max_binlog_size 设置每个binlog文件的大小
实现方式	redo log 是 InnoDB 引擎层实现的,并不是所有引擎都有             binlog 是 Server 层实现的,所有引擎都可以使用 binlog 日志
记录方式	redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志   binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上
适用场景	redo log 适用于崩溃恢复(crash-safe)	                      binlog 适用于主从复制和数据恢复

=================================================
undo log
数据库事务四大特性中有一个是 原子性 ，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。实际上， 原子性 底层就是通过 undo log 实现的。 undo log 主要记录了数据的逻辑变化，比如一条 ` INSERT 语句，对应一条 DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的 undo log ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， undo log 也是 MVCC(多版本并发控制)实现的关键

链接：https://www.jianshu.com/p/ddd7d6e058dd
对比:
undo log和redo logo都是InnoDB的功能，都是事务日志
undo log是逻辑日志，记录是操作记录日志，redo log是物理日志，记录的是新数据
undo log是为了保证事务原子性而设计的，redo log是为了保证事务持久性设置的。undo log在InnoDB中用来实现多版本控制，执行rollback操作时，undo log可以作为事务回滚的快照读参考，而redo log是备份的最新数据位置，系统冗机时，只要重启mysql服务，就可以将未持久保存的数据持久到磁盘

=================================================
https://www.cnblogs.com/geaozhang/p/7214257.html
=================================================







=================================================
mysql double write:

关于IO的最小单位:
1. 数据库IO的最小单位是16K(MySQL默认)
2. 文件系统IO的最小单位是4K(也有1K的)
3. 磁盘IO的最小单位是512字节

因此，存在IO写入导致page损坏的风险

doublewrite提高innodb的可靠性，用来解决部分写失败(partial page write页断裂)


eg: 我在mysql有1个页(16k)要刷进磁盘, 磁盘在要写4次(4K * 4),磁盘写了2k的时候, 掉电了
也就是说前2K数据是新的，后14K是旧的，那么磁盘数据库这个数据页就是不完整的，是一个坏掉的数据页。redo只能加上旧、校检完整的数据页恢复一个脏块，不能修复坏掉的数据页，所以这个数据就丢失了，可能会造成数据不一致，所以需要double write。

使用情景
当数据库正在从内存想磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失。这时是无法通过重做日志恢复的，因为重做日志记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力。

doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M。

1. 当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中；
2. 接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB；
3. 待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖)


Q:为什么log write不需要doublewrite的支持？
A:因为redolog写入的单位就是512字节，也就是磁盘IO的最小单位，所以无所谓数据损坏。


3. doublewrite的副作用
double write带来的写负载
　　1. double write是一个buffer, 但其实它是开在物理文件上的一个buffer(mmap), 其实也就是file, 所以它会导致系统有更多的fsync操作, 而硬盘的fsync性能是很慢的, 所以它会降低mysql的整体性能。
　　2. 但是，doublewrite buffer写入磁盘共享表空间这个过程是连续存储，是顺序写，性能非常高，(约占写的%10)，牺牲一点写性能来保证数据页的完整还是很有必要的。

不怕数据损坏和丢失可以关闭double write

4. 为什么没有把double write里面的数据写到data page里面呢？
    1. double write里面的数据是连续的，如果直接写到data page里面，而data page的页又是离散的，写入会很慢。
    2. double write里面的数据没有办法被及时的覆盖掉，导致double write的压力很大；短时间内可能会出现double write溢出的情况。(顺序写, 可以写完; 如果是离散写, 可能写不完让double write溢出)
=================================================


todo:
1. 强制读主线程
为运营平台提供活动以及商品等多维度搜索功能.(阳斌的esScript, 活动名和商品名是怎么存进一个字段的)
2. feed流是怎么设计的
3. 单个团长可视为服务的一个租户, 不能用有限的机器为租户提供不限量的服务. 因此接入Sentinel, 对核心接口进行限流, 防止服务被打垮. 怎么处理母团子团孙团的.
4. kouchengdi, 怎么处理cdn切量问题的.
数据库闪断的兜底措施: 会不会断线重连, 漏了的数据要不要补怎么补
5. 数据同步适配器
6. 开放平台, appId appKey appSecret, 校验
7. 单点登录流程

上午发现有数据库有慢查询，老张安排查询慢查询问题， 通过排查，发现慢查询 消耗数据库CPU高的原因是阿里云 全量备份导致 1.5H
吴魁, feed没走索引

4. redis怎么处理热key

记账重构, 记账是不是可以直接给支付组了
